{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from KEYS.secrets import OPENAI_API_KEY, LANGCHAIN_API_KEY\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Environmental Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]=OPENAI_API_KEY\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"Langchain_Learn1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Input Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\n",
      "\n",
      "There are no official \"wonders of the world\" designated in Nepal, but there are certainly many amazing sights and cultural landmarks that could be considered wonders. Some examples include:\n",
      "\n",
      "1. Mount Everest - the highest mountain in the world and a marvel of nature\n",
      "2. Pashupatinath Temple - a sacred Hindu temple complex and UNESCO World Heritage Site\n",
      "3. Chitwan National Park - a diverse and stunning natural reserve, home to many rare and endangered species\n",
      "4. Boudhanath Stupa - one of the largest Buddhist stupas in the world and an important pilgrimage site\n",
      "5. Durbar Square in Kathmandu - a complex of ancient palaces, temples, and courtyards, showcasing Nepal's rich history and architecture\n",
      "6. Annapurna Circuit - a popular trekking route that offers breathtaking views of the Himalayas\n",
      "7. Lumbini - the birthplace of Buddha and a significant pilgrimage site for Buddhists\n",
      "8. Bhaktapur - a well-preserved medieval city with beautiful architecture and traditional Newari culture\n",
      "9. Sagarmatha National Park - another UNESCO World Heritage Site, home to diverse flora and fauna and the famous Mt. Everest.\n",
      "10. Ghorepani Poon Hill Trek - a picturesque\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"How many wonders of the world are in Nepal\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The 2012 Olympics were held in London, England."
     ]
    }
   ],
   "source": [
    "for chunk in llm.stream(\"Where were the 2012 Olympics held?\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chat Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am associated with Nike.\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.messages import HumanMessage, SystemMessage\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are Micheal Jordan.\"),\n",
    "    HumanMessage(content=\"Which shoe manufacturer are you associated with?\"),\n",
    "]\n",
    "response = chat.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me a funny joke about robots.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Simple prompt with placeholders\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a {adjective} joke about {content}.\"\n",
    ")\n",
    "\n",
    "# Filling placeholders to create a prompt\n",
    "filled_prompt = prompt_template.format(adjective=\"funny\", content=\"robots\")\n",
    "print(filled_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='You are a helpful AI bot. Your name is Bob.'\n",
      "content='Hello, how are you doing?'\n",
      "content=\"I'm doing well, thanks!\"\n",
      "content='What is your name?'\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Defining a chat prompt with various roles\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "        (\"human\", \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thanks!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Formatting the chat prompt\n",
    "formatted_messages = chat_template.format_messages(name=\"Bob\", user_input=\"What is your name?\")\n",
    "for message in formatted_messages:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Parsers\n",
    "\n",
    "\n",
    "#### PydanticOutputParsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.pydantic_v1 import BaseModel, Field, validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your desired data structure using Pydantic\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "    @validator(\"setup\")\n",
    "    def question_ends_with_question_mark(cls, field):\n",
    "        if field[-1] != \"?\":\n",
    "            raise ValueError(\"Badly formed question!\")\n",
    "        return field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a PydanticOutputParser\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "# Create a prompt with format instructions\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup='Why did the tomato turn red?' punchline='Because it saw the salad dressing!'\n"
     ]
    }
   ],
   "source": [
    "# Define a query to prompt the language model\n",
    "query = \"Tell me a joke.\"\n",
    "\n",
    "# Combine prompt, model, and parser to get structured output\n",
    "prompt_and_model = prompt | model\n",
    "output = prompt_and_model.invoke({\"query\": query})\n",
    "\n",
    "# Parse the output using the parser\n",
    "parsed_result = parser.invoke(output)\n",
    "\n",
    "# The result is a structured object\n",
    "print(parsed_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SimpleJsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'birthdate': 'June 28, 1971', 'birthplace': 'Pretoria, South Africa'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "\n",
    "# Create a JSON prompt\n",
    "json_prompt = PromptTemplate.from_template(\n",
    "    \"Return a JSON object with `birthdate` and `birthplace` key that answers the following question: {question}\"\n",
    ")\n",
    "\n",
    "# Initialize the JSON parser\n",
    "json_parser = SimpleJsonOutputParser()\n",
    "\n",
    "# Create a chain with the prompt, model, and parser\n",
    "json_chain = json_prompt | model | json_parser\n",
    "\n",
    "# Stream through the results\n",
    "result_list = list(json_chain.stream({\"question\": \"When and where was Elon Musk born?\"}))\n",
    "\n",
    "# The result is a list of JSON-like dictionaries\n",
    "print(result_list[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CommaSeparatedListOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aayush/Documents/Fusemachines/Langchain_Upskilling/env/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1. Manchester City\\n2. Manchester United\\n3. Liverpool\\n4. Chelsea\\n5. Arsenal']\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "# Initialize the parser\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "# Create format instructions\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "# Create a prompt to request a list\n",
    "prompt = PromptTemplate(\n",
    "    template=\"List five {subject}.\\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n",
    "# Define a query to prompt the model\n",
    "query = \"English Premier League Teams\"\n",
    "\n",
    "# Generate the output\n",
    "output = model(prompt.format(subject=query))\n",
    "\n",
    "# Parse the output using the parser\n",
    "parsed_result = output_parser.parse(output)\n",
    "\n",
    "# The result is a list of items\n",
    "print(parsed_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DatetimeOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1969-07-20 20:17:40\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "# Initialize the DatetimeOutputParser\n",
    "output_parser = DatetimeOutputParser()\n",
    "\n",
    "# Create a prompt with format instructions\n",
    "template = \"\"\"\n",
    "Answer the user's question:\n",
    "{question}\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    template,\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# Create a chain with the prompt and language model\n",
    "llm = OpenAI()\n",
    "chain = prompt | llm\n",
    "# Define a query to prompt the model\n",
    "query = \"when did Neil Armstrong land on the moon in terms of GMT?\"\n",
    "\n",
    "# Run the chain\n",
    "output = chain.invoke(query)\n",
    "\n",
    "# Parse the output using the datetime parser\n",
    "parsed_result = output_parser.parse(output)\n",
    "\n",
    "# The result is a datetime object\n",
    "print(parsed_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
